---
title: "Importing Data"
format: html
---

```{r include=FALSE}
library(readr)
library(readxl)
library(countdown)
library(dplyr)
library(datasets)
library(openxlsx)
```

So far, we have only made use of data which is pre-loaded into R via packages, but it is also possible to load your own data in from a variety of sources. We will focus on two different file types;

-   CSV
-   Excel

## Local Reading

As described in Chapter 1, the bottom right pane of RStudio allows you to view files that are within your own personal filesystem. You are free to create new folders in this area, using the `New Folder` button.

```{r}
#| echo: False

countdown(minutes = 5, seconds = 0, style = "position: relative; width: min-content;")
```

1.  Navigate to the `Files` at the bottom right pane of your RStudio
2.  Create a new folder called `data`
3.  Save this [GCP dataset](https://github.com/cmbsteinberg/knbs_intro/blob/main/data/gcp.csv) to this folder as `gcp.csv`. You will need to press the download button in the top right corner.

```{r, echo=TRUE}
read_csv("data/gcp.csv")
```

Great, we will come back to using these two files, but first let's discuss how to read in csv files.

## CSV

Although there is a `read.csv()` function in base R, like most things there is a better `tidyverse` alternative! `read_csv()` from the `readr` package reads CSVs in as a tibble (which has additional features compared to a standard data frame), is much faster (\~10X), and allows you to specify how you read data in more easily.

As always, let's read the function documentation using `?read_csv`. This tells us we need to provide a path to the file. This path can be either local or remote; so it will work equally well for data inside your project or from the internet.

To read in a local file, you have to specify the exact location of the file. You can do this as either an *absolute* filepath, which starts from the drive name right through to the final file (e.g. C:/Documents/My_work/file.csv), or as a *relative* file path. A relative file path just gives the location of the file starting from your current working environment. You can check what your current working environment is using the command `getwd()`. The advantage of using relative file paths is if someone duplicates your project from Github, the code will still work on their own computer.

We will start by reading in some local data, which contains details of Kenyan Gross County Product by economic activity for 2017:

```{r use_read_csv, eval=FALSE}
gcp <- read_csv("data/gcp.csv")
```

Notice that the file is inside the **data** folder inside the current working directory.

`gcp` will now show in your environment. The environment viewer (top right) shows you basic information about the data that has been loaded in. You can also click on any object to view it in your script window.

You can also read in data directly from the web using the same function. For example, with the same GCP data

```{r, eval = T}
gcp_ <- read_csv("https://raw.githubusercontent.com/cmbsteinberg/knbs_intro/refs/heads/main/data/gcp.csv")
```

This works exactly the same way as reading in local data, and the object you have created will appear in your environment (top right).

### Exercise

```{r}
#| echo: False

countdown(minutes = 5,
          seconds = 0,
          style = "position: relative; width: min-content;")
```

1.  Read in the frogs dataset found here:'<https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-08-02/frogs.csv>' as an object called `frogs`


```{r, include = TRUE}
#| code-fold: true
#| code-summary: "Solution"
frogs <- read.csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-08-02/frogs.csv")

```


### Inspecting the dataset

As noted in the previous section, you can see by looking in the environment window that the eurovision dataset has 48 observations and 22 variables. You can also return this information (and more) about datasets programatically, using the `glimpse()` function, again from the dplyr package:

```{r}
glimpse(gcp)
```

As well as returning the number of rows and columns in the data, the glimpse function also shows you the names of the columns, the column classes (indicated in <triangular brackets>), and an example of the first few rows of data.

### Exercise

```{r}
#| echo: False

countdown(minutes = 5, seconds = 0, style = "position: relative; width: min-content;")
```
1.  Use the glimpse and View functions to examine the frogs dataset. How many rows and columns does it have?


```{r, eval = FALSE}
#| code-fold: true
#| code-summary: "Solution"
View(frogs)

glimpse(frogs)
```


## Excel

Reading excel files works in much the same way as CSV files. However, due to the difference in underlying structures we require the function `read_excel()` from a different package called `readxl`.

The main difference when reading excel files is three additional arguments that we can set;

-   `sheet` which allows us to specify which sheet to read. It can take the form of a string (the name of the sheet) or an integer (the position of the sheet); and
-   `range` which allows us to specify a cell range. It takes a typical cell reference like "B3:D10".
-   `skip` an alternative to specifying a cell range, you can simply indicate how many rows to skip at the start of the sheet. This is ideal if you want to read in a sheet with an unknown number of columns and/or rows, but know there are several lines of metadata at the top of the sheet.

If we don't set any of these arguments it will assume our data is in the first row of the first sheet (and it becomes almost identical to read_csv above).

```{r, eval = FALSE}
# One option is to download the file 
tourism <- read_excel("data/tourism.xlsx")
```

### Exercise

```{r}
#| echo: False

countdown(minutes = 10, seconds = 0, style = "position: relative; width: min-content;")
```

1.  Install and load the readxl package.
2.  Download this [dataset published by KNBS about the tourism sector]("https://www.knbs.or.ke/wp-content/uploads/2024/04/2023-Economic-Survey-Kenya-Tourism-Sector.xlsx"), saving it into /data
3.  Read it in, specifying the sheet name you want to read in.
4.  Examine the data you have read in; are the column names what you want? Work out how to skip these and only read in the data, with the correct column names.


```{r, eval = FALSE}
#| code-fold: true
#| code-summary: "Solution"
url = "https://www.knbs.or.ke/wp-content/uploads/2024/04/2023-Economic-Survey-Kenya-Tourism-Sector.xlsx"
download_first <- download.file(url,destfile = "data/tourism.xlsx")
tourism <- read_excel("data/tourism.xlsx", sheet = "Table 12.5", skip = 2)
```

## Rio

Sometimes you may want to read a selection of files of all different types. This is where `Rio` can come in handy. `Rio` is a wrapper around the libraries we've used above and many more, which lets you use `import()` to read almost any file in. This isn't always useful, when you want to do very specific things with a certain file, but can be much cleaner.

## Column Names

In the previous section we looked at reading data into R and also inspecting it. In this section we are going to look at our first steps once it's read in.

In the previous session we stated that every column in a data frame is a variable and it is good practice to not have spaces within variable names, as spaces makes it harder for us to call on the variables when we need to use them.

When you enter data in Excel, you most often don’t think too much about what you call each column. After all, you just label them once and as long as they are meaningful to you, what does it matter if the column name is a long combination of CAPITALLETTERS, lowercaseletters, and numbers?

When you are working with variables in R though, you need to type the name of each variable, every time you want to work with it. So, it makes sense to make your column names as simple, but meaningful as possible.

> **Ideally, they should also be consistently formatted.**

For example if we wanted to pick the `name of Passenger` column from the Titanic dataset.

```{r, eval = FALSE}
Titanic$name Of Passenger
```

To get around this we enclose `name of passenger` with back ticks like the code below - this is the key above the tab key on the left hand side of your keyboard.

```{r, eval = FALSE}
# Selecting data using the $ symbol
# note this now works because of the back ticks
Titanic$`name Of Passenger`
```

If your column names have spaces and you don’t get rid of them, you must use backticks.

However its good practise to remove spaces and symbols.

We can see the column names by using the `names()` function to access the `name` attribute of the data.

```{r}
# Getting the column names using the names function

names(Titanic)
```

As we can see our column names have spaces and some start with capital letters and some with small letters, we can clean the names using the `janitor` package.

### Cleaning Column Names

The `janitor` package offers many functions used to manipulate data, for example removing empty rows and columns, finding duplicates within a data frame. In this session we will use the library to to clean our data set names.

We can clean the names of our dataset with the `janitor::clean_names()` function as shown below.

We are overwriting the original Titanic data frame with a version with the column names cleaned.

```{r}
# Cleaning the column names using the janitor
# package and the clean_names() function.
# This will put all names in lower case letters and 
# replace blank spaces with underscores.

titanic <- janitor::clean_names(Titanic)

# Getting the column names of the dataset

names(titanic)
```

`clean_names()` removes spaces, symbols, changes characters to lower case and makes all columns start with letters.

This is the default setting, there are many other options such as `snake`, `lower_camel` and `all_caps`. These can be put inside the `clean_names()` function as shown below:

```{r}
# Specifying the case within the clean_names function

janitor::clean_names(Titanic, case = "snake")
```
